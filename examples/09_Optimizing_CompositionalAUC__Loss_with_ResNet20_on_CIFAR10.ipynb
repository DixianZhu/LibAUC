{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_Optimizing_CompositionalAUC _Loss_with_ResNet20_on_CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Author: Zhuoning Yuan\n",
        "* Project: https://github.com/Optimization-AI/LibAUC\n"
      ],
      "metadata": {
        "id": "zUv-WIY5h1Dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Citation**"
      ],
      "metadata": {
        "id": "sN_0N73OsRkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "If you use this work,  please acknowledge our library and cite the following paper:\n",
        "```\n",
        "@inproceedings{\n",
        "    yuan2022compositional,\n",
        "    title={Compositional Training for End-to-End Deep {AUC} Maximization},\n",
        "    author={Zhuoning Yuan and Zhishuai Guo and Nitesh Chawla and Tianbao Yang},\n",
        "    booktitle={International Conference on Learning Representations},\n",
        "    year={2022},\n",
        "    url={https://openreview.net/forum?id=gPvB4pdu_Z}\n",
        "}\n",
        "```\n",
        "```\n",
        "@inproceedings{yuan2021robust,\n",
        "\ttitle={Large-scale Robust Deep AUC Maximization: A New Surrogate Loss and Empirical Studies on Medical Image Classification},\n",
        "\tauthor={Yuan, Zhuoning and Yan, Yan and Sonka, Milan and Yang, Tianbao},\n",
        "\tbooktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},\n",
        "\tyear={2021}\n",
        "\t}\n",
        "```"
      ],
      "metadata": {
        "id": "cmoCMfbXsUQz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing LibAUC**"
      ],
      "metadata": {
        "id": "DEavjKBdh8hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install libauc==1.1.9rc1"
      ],
      "metadata": {
        "id": "6zYjONxCh5Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing LibAUC**"
      ],
      "metadata": {
        "id": "6m-DLkddiPT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from libauc.losses import CompositionalLoss\n",
        "from libauc.optimizers import PDSCA\n",
        "from libauc.models import ResNet20\n",
        "from libauc.datasets import CIFAR10, CIFAR100, CAT_VS_DOG, STL10 \n",
        "from libauc.datasets import ImbalanceGenerator\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "7oZv1TakiUBF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reproducibility**"
      ],
      "metadata": {
        "id": "Kd57DCDOilVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "-dUoQpz5imKD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Dataset**"
      ],
      "metadata": {
        "id": "Y2wT1qzXiqCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=32, crop_size=30, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([                                                \n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.RandomCrop((crop_size, crop_size), padding=None),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        if self.mode == 'train':\n",
        "            image = self.transform_train(image)\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "        return image, target"
      ],
      "metadata": {
        "id": "kCEq4vNairrd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Paramaters**"
      ],
      "metadata": {
        "id": "J3FgOKRPivmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all paramaters\n",
        "total_epochs = 200 \n",
        "SEED = 123\n",
        "dataset = 'C2' # choose dataset to use\n",
        "imratio = 0.1\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# tunable paramaters\n",
        "margin = 1.0\n",
        "lr = 0.1  \n",
        "#lr0 = 0.1 # refers to line 5 in algorithm 1. By default, lr0=lr unless you specify the value and pass it to optimizer\n",
        "gamma = 500 \n",
        "weight_decay = 1e-4\n",
        "beta1 = 0.9   # try different values: e.g., [0.999, 0.99, 0.9]\n",
        "beta2 = 0.999 # try different values: e.g., [0.999, 0.99, 0.9] "
      ],
      "metadata": {
        "id": "g8ReDBxeixFw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading datasets**"
      ],
      "metadata": {
        "id": "Mmv9mBdvjA4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if dataset == 'C10':\n",
        "    IMG_SIZE = 32\n",
        "    (train_data, train_label), (test_data, test_label) = CIFAR10()\n",
        "elif dataset == 'C100':\n",
        "    IMG_SIZE = 32\n",
        "    (train_data, train_label), (test_data, test_label) = CIFAR100()\n",
        "elif dataset == 'STL10':\n",
        "    BATCH_SIZE = 32\n",
        "    IMG_SIZE = 96\n",
        "    (train_data, train_label), (test_data, test_label) = STL10()\n",
        "elif dataset == 'C2':\n",
        "    IMG_SIZE = 50\n",
        "    (train_data, train_label), (test_data, test_label) = CAT_VS_DOG()\n",
        "\n",
        "(train_images, train_labels) = ImbalanceGenerator(train_data, train_label, imratio=imratio, shuffle=True, random_seed=0) # fixed seed\n",
        "(test_images, test_labels) = ImbalanceGenerator(test_data, test_label, is_balanced=True,  random_seed=0)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(ImageDataset(train_images, train_labels, image_size=IMG_SIZE, crop_size=IMG_SIZE-2), batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=False, drop_last=True)\n",
        "testloader = torch.utils.data.DataLoader(ImageDataset(test_images, test_labels, image_size=IMG_SIZE, crop_size=IMG_SIZE-2, mode='test'), batch_size=BATCH_SIZE, shuffle=False, num_workers=8,  pin_memory=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7fCXryRjB1Z",
        "outputId": "66919ce0-cf7a-4d2c-b921-a01fc3628890"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from  https://homepage.divms.uiowa.edu/~zhuoning/datasets/cat_vs_dog.tar.gz\n",
            "233422848/233417984 [==============================] - 8s 0us/step\n",
            "NUM_SAMPLES: [11128], POS:NEG: [1112 : 10016], POS_RATIO: 0.0999\n",
            "NUM_SAMPLES: [5000], POS:NEG: [2516 : 2484], POS_RATIO: 0.5032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training**"
      ],
      "metadata": {
        "id": "yreaM0sSjQj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_all_seeds(123)\n",
        "model = ResNet20(pretrained=False, last_activation=None, activations='relu', num_classes=1)\n",
        "model = model.cuda()\n",
        "    \n",
        "# Compositional Training\n",
        "Loss = CompositionalLoss(imratio=imratio)  \n",
        "optimizer = PDSCA(model, \n",
        "                  a=Loss.a, \n",
        "                  b=Loss.b, \n",
        "                  alpha=Loss.alpha, \n",
        "                  lr=lr,\n",
        "                  beta1=beta1,\n",
        "                  beta2=beta2, \n",
        "                  gamma=gamma, \n",
        "                  margin=margin, \n",
        "                  weight_decay=weight_decay)\n",
        "\n",
        "test_auc_max = 0\n",
        "print ('-'*30)\n",
        "for epoch in range(total_epochs):\n",
        "    if epoch == int(0.5*total_epochs) or epoch==int(0.75*total_epochs):\n",
        "      optimizer.update_regularizer(decay_factor=10)\n",
        "\n",
        "    train_pred = []\n",
        "    train_true = []\n",
        "    for idx, (data, targets) in enumerate(trainloader):\n",
        "        model.train()  \n",
        "        data, targets  = data.cuda(), targets.cuda()\n",
        "        y_pred = model(data)\n",
        "        loss = Loss(y_pred, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_pred.append(y_pred.cpu().detach().numpy())\n",
        "        train_true.append(targets.cpu().detach().numpy())\n",
        "    \n",
        "    train_true = np.concatenate(train_true)\n",
        "    train_pred = np.concatenate(train_pred)\n",
        "    train_auc = roc_auc_score(train_true, train_pred) \n",
        "    \n",
        "    # evaluations\n",
        "    model.eval()\n",
        "    test_pred = []\n",
        "    test_true = [] \n",
        "    for j, data in enumerate(testloader):\n",
        "        test_data, test_targets = data\n",
        "        test_data = test_data.cuda()\n",
        "        outputs = model(test_data)\n",
        "        y_pred = torch.sigmoid(outputs)\n",
        "        test_pred.append(y_pred.cpu().detach().numpy())\n",
        "        test_true.append(test_targets.numpy())\n",
        "    test_true = np.concatenate(test_true)\n",
        "    test_pred = np.concatenate(test_pred)\n",
        "    val_auc =  roc_auc_score(test_true, test_pred) \n",
        "    model.train()\n",
        "\n",
        "    if test_auc_max<val_auc:\n",
        "       test_auc_max = val_auc\n",
        "      \n",
        "    # print results\n",
        "    print(\"epoch: {}, train_auc:{:4f}, test_auc:{:4f}, test_auc_max:{:4f}\".format(epoch, train_auc, val_auc, test_auc_max, optimizer.lr ))          "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2cuzzOhh-NA",
        "outputId": "fb8eb9c6-585d-411d-af0b-a92d685d0fc7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "epoch: 0, train_auc:0.616761, test_auc:0.623856, test_auc_max:0.623856\n",
            "epoch: 1, train_auc:0.683287, test_auc:0.668705, test_auc_max:0.668705\n",
            "epoch: 2, train_auc:0.706854, test_auc:0.695609, test_auc_max:0.695609\n",
            "epoch: 3, train_auc:0.718007, test_auc:0.721402, test_auc_max:0.721402\n",
            "epoch: 4, train_auc:0.728789, test_auc:0.731166, test_auc_max:0.731166\n",
            "epoch: 5, train_auc:0.744389, test_auc:0.729358, test_auc_max:0.731166\n",
            "epoch: 6, train_auc:0.759461, test_auc:0.739063, test_auc_max:0.739063\n",
            "epoch: 7, train_auc:0.763460, test_auc:0.740313, test_auc_max:0.740313\n",
            "epoch: 8, train_auc:0.767668, test_auc:0.760257, test_auc_max:0.760257\n",
            "epoch: 9, train_auc:0.782970, test_auc:0.781897, test_auc_max:0.781897\n",
            "epoch: 10, train_auc:0.791637, test_auc:0.770308, test_auc_max:0.781897\n",
            "epoch: 11, train_auc:0.808350, test_auc:0.769889, test_auc_max:0.781897\n",
            "epoch: 12, train_auc:0.816112, test_auc:0.791682, test_auc_max:0.791682\n",
            "epoch: 13, train_auc:0.819606, test_auc:0.790049, test_auc_max:0.791682\n",
            "epoch: 14, train_auc:0.826151, test_auc:0.788186, test_auc_max:0.791682\n",
            "epoch: 15, train_auc:0.829881, test_auc:0.786387, test_auc_max:0.791682\n",
            "epoch: 16, train_auc:0.844002, test_auc:0.813322, test_auc_max:0.813322\n",
            "epoch: 17, train_auc:0.847787, test_auc:0.812036, test_auc_max:0.813322\n",
            "epoch: 18, train_auc:0.846933, test_auc:0.815117, test_auc_max:0.815117\n",
            "epoch: 19, train_auc:0.852943, test_auc:0.844398, test_auc_max:0.844398\n",
            "epoch: 20, train_auc:0.861389, test_auc:0.838710, test_auc_max:0.844398\n",
            "epoch: 21, train_auc:0.867745, test_auc:0.831930, test_auc_max:0.844398\n",
            "epoch: 22, train_auc:0.874651, test_auc:0.773722, test_auc_max:0.844398\n",
            "epoch: 23, train_auc:0.864924, test_auc:0.839847, test_auc_max:0.844398\n",
            "epoch: 24, train_auc:0.873314, test_auc:0.775928, test_auc_max:0.844398\n",
            "epoch: 25, train_auc:0.879947, test_auc:0.837623, test_auc_max:0.844398\n",
            "epoch: 26, train_auc:0.883466, test_auc:0.678908, test_auc_max:0.844398\n",
            "epoch: 27, train_auc:0.887079, test_auc:0.804637, test_auc_max:0.844398\n",
            "epoch: 28, train_auc:0.893487, test_auc:0.806526, test_auc_max:0.844398\n",
            "epoch: 29, train_auc:0.894231, test_auc:0.842656, test_auc_max:0.844398\n",
            "epoch: 30, train_auc:0.897523, test_auc:0.831206, test_auc_max:0.844398\n",
            "epoch: 31, train_auc:0.902803, test_auc:0.869382, test_auc_max:0.869382\n",
            "epoch: 32, train_auc:0.902252, test_auc:0.815075, test_auc_max:0.869382\n",
            "epoch: 33, train_auc:0.904636, test_auc:0.865399, test_auc_max:0.869382\n",
            "epoch: 34, train_auc:0.909176, test_auc:0.865846, test_auc_max:0.869382\n",
            "epoch: 35, train_auc:0.914066, test_auc:0.812264, test_auc_max:0.869382\n",
            "epoch: 36, train_auc:0.912760, test_auc:0.881944, test_auc_max:0.881944\n",
            "epoch: 37, train_auc:0.917527, test_auc:0.864082, test_auc_max:0.881944\n",
            "epoch: 38, train_auc:0.917474, test_auc:0.879787, test_auc_max:0.881944\n",
            "epoch: 39, train_auc:0.915523, test_auc:0.731289, test_auc_max:0.881944\n",
            "epoch: 40, train_auc:0.926328, test_auc:0.879365, test_auc_max:0.881944\n",
            "epoch: 41, train_auc:0.922508, test_auc:0.888712, test_auc_max:0.888712\n",
            "epoch: 42, train_auc:0.929307, test_auc:0.833963, test_auc_max:0.888712\n",
            "epoch: 43, train_auc:0.927215, test_auc:0.861088, test_auc_max:0.888712\n",
            "epoch: 44, train_auc:0.928494, test_auc:0.858524, test_auc_max:0.888712\n",
            "epoch: 45, train_auc:0.932042, test_auc:0.872449, test_auc_max:0.888712\n",
            "epoch: 46, train_auc:0.934529, test_auc:0.852763, test_auc_max:0.888712\n",
            "epoch: 47, train_auc:0.934474, test_auc:0.828596, test_auc_max:0.888712\n",
            "epoch: 48, train_auc:0.932363, test_auc:0.895264, test_auc_max:0.895264\n",
            "epoch: 49, train_auc:0.934612, test_auc:0.882333, test_auc_max:0.895264\n",
            "epoch: 50, train_auc:0.947456, test_auc:0.892481, test_auc_max:0.895264\n",
            "epoch: 51, train_auc:0.941754, test_auc:0.886039, test_auc_max:0.895264\n",
            "epoch: 52, train_auc:0.945527, test_auc:0.891719, test_auc_max:0.895264\n",
            "epoch: 53, train_auc:0.941842, test_auc:0.857678, test_auc_max:0.895264\n",
            "epoch: 54, train_auc:0.942115, test_auc:0.894303, test_auc_max:0.895264\n",
            "epoch: 55, train_auc:0.948914, test_auc:0.865337, test_auc_max:0.895264\n",
            "epoch: 56, train_auc:0.949810, test_auc:0.865400, test_auc_max:0.895264\n",
            "epoch: 57, train_auc:0.951677, test_auc:0.902818, test_auc_max:0.902818\n",
            "epoch: 58, train_auc:0.950338, test_auc:0.874303, test_auc_max:0.902818\n",
            "epoch: 59, train_auc:0.949529, test_auc:0.859869, test_auc_max:0.902818\n",
            "epoch: 60, train_auc:0.949829, test_auc:0.830852, test_auc_max:0.902818\n",
            "epoch: 61, train_auc:0.949307, test_auc:0.884271, test_auc_max:0.902818\n",
            "epoch: 62, train_auc:0.960023, test_auc:0.911373, test_auc_max:0.911373\n",
            "epoch: 63, train_auc:0.956047, test_auc:0.902043, test_auc_max:0.911373\n",
            "epoch: 64, train_auc:0.953743, test_auc:0.901275, test_auc_max:0.911373\n",
            "epoch: 65, train_auc:0.956872, test_auc:0.898684, test_auc_max:0.911373\n",
            "epoch: 66, train_auc:0.960431, test_auc:0.861636, test_auc_max:0.911373\n",
            "epoch: 67, train_auc:0.959838, test_auc:0.889527, test_auc_max:0.911373\n",
            "epoch: 68, train_auc:0.958931, test_auc:0.839133, test_auc_max:0.911373\n",
            "epoch: 69, train_auc:0.959415, test_auc:0.906921, test_auc_max:0.911373\n",
            "epoch: 70, train_auc:0.955339, test_auc:0.899893, test_auc_max:0.911373\n",
            "epoch: 71, train_auc:0.961984, test_auc:0.901645, test_auc_max:0.911373\n",
            "epoch: 72, train_auc:0.958353, test_auc:0.861607, test_auc_max:0.911373\n",
            "epoch: 73, train_auc:0.965664, test_auc:0.834729, test_auc_max:0.911373\n",
            "epoch: 74, train_auc:0.964639, test_auc:0.903881, test_auc_max:0.911373\n",
            "epoch: 75, train_auc:0.964991, test_auc:0.916367, test_auc_max:0.916367\n",
            "epoch: 76, train_auc:0.962149, test_auc:0.891149, test_auc_max:0.916367\n",
            "epoch: 77, train_auc:0.962973, test_auc:0.899587, test_auc_max:0.916367\n",
            "epoch: 78, train_auc:0.966100, test_auc:0.857964, test_auc_max:0.916367\n",
            "epoch: 79, train_auc:0.966045, test_auc:0.904417, test_auc_max:0.916367\n",
            "epoch: 80, train_auc:0.964414, test_auc:0.919535, test_auc_max:0.919535\n",
            "epoch: 81, train_auc:0.966390, test_auc:0.879529, test_auc_max:0.919535\n",
            "epoch: 82, train_auc:0.966993, test_auc:0.921622, test_auc_max:0.921622\n",
            "epoch: 83, train_auc:0.969030, test_auc:0.906483, test_auc_max:0.921622\n",
            "epoch: 84, train_auc:0.965468, test_auc:0.903577, test_auc_max:0.921622\n",
            "epoch: 85, train_auc:0.967294, test_auc:0.843769, test_auc_max:0.921622\n",
            "epoch: 86, train_auc:0.967180, test_auc:0.912850, test_auc_max:0.921622\n",
            "epoch: 87, train_auc:0.972584, test_auc:0.891544, test_auc_max:0.921622\n",
            "epoch: 88, train_auc:0.974000, test_auc:0.905673, test_auc_max:0.921622\n",
            "epoch: 89, train_auc:0.977801, test_auc:0.907317, test_auc_max:0.921622\n",
            "epoch: 90, train_auc:0.969692, test_auc:0.868995, test_auc_max:0.921622\n",
            "epoch: 91, train_auc:0.975432, test_auc:0.903089, test_auc_max:0.921622\n",
            "epoch: 92, train_auc:0.973348, test_auc:0.905226, test_auc_max:0.921622\n",
            "epoch: 93, train_auc:0.970734, test_auc:0.901771, test_auc_max:0.921622\n",
            "epoch: 94, train_auc:0.969287, test_auc:0.900061, test_auc_max:0.921622\n",
            "epoch: 95, train_auc:0.972455, test_auc:0.894744, test_auc_max:0.921622\n",
            "epoch: 96, train_auc:0.972120, test_auc:0.901410, test_auc_max:0.921622\n",
            "epoch: 97, train_auc:0.976386, test_auc:0.905748, test_auc_max:0.921622\n",
            "epoch: 98, train_auc:0.975974, test_auc:0.883342, test_auc_max:0.921622\n",
            "epoch: 99, train_auc:0.976287, test_auc:0.926817, test_auc_max:0.926817\n",
            "Reducing learning rate to 0.01000 (0.01000) @ T=8600!\n",
            "Updating regularizer @ T=8600!\n",
            "epoch: 100, train_auc:0.987790, test_auc:0.939062, test_auc_max:0.939062\n",
            "epoch: 101, train_auc:0.990576, test_auc:0.938942, test_auc_max:0.939062\n",
            "epoch: 102, train_auc:0.992462, test_auc:0.938899, test_auc_max:0.939062\n",
            "epoch: 103, train_auc:0.993282, test_auc:0.938828, test_auc_max:0.939062\n",
            "epoch: 104, train_auc:0.994174, test_auc:0.939626, test_auc_max:0.939626\n",
            "epoch: 105, train_auc:0.994817, test_auc:0.938269, test_auc_max:0.939626\n",
            "epoch: 106, train_auc:0.995400, test_auc:0.939204, test_auc_max:0.939626\n",
            "epoch: 107, train_auc:0.995415, test_auc:0.940122, test_auc_max:0.940122\n",
            "epoch: 108, train_auc:0.996261, test_auc:0.937032, test_auc_max:0.940122\n",
            "epoch: 109, train_auc:0.996766, test_auc:0.936758, test_auc_max:0.940122\n",
            "epoch: 110, train_auc:0.997040, test_auc:0.939041, test_auc_max:0.940122\n",
            "epoch: 111, train_auc:0.996546, test_auc:0.935381, test_auc_max:0.940122\n",
            "epoch: 112, train_auc:0.996852, test_auc:0.932653, test_auc_max:0.940122\n",
            "epoch: 113, train_auc:0.997911, test_auc:0.934689, test_auc_max:0.940122\n",
            "epoch: 114, train_auc:0.997447, test_auc:0.935060, test_auc_max:0.940122\n",
            "epoch: 115, train_auc:0.996825, test_auc:0.935007, test_auc_max:0.940122\n",
            "epoch: 116, train_auc:0.998201, test_auc:0.932869, test_auc_max:0.940122\n",
            "epoch: 117, train_auc:0.998252, test_auc:0.934429, test_auc_max:0.940122\n",
            "epoch: 118, train_auc:0.998205, test_auc:0.930923, test_auc_max:0.940122\n",
            "epoch: 119, train_auc:0.998308, test_auc:0.934028, test_auc_max:0.940122\n",
            "epoch: 120, train_auc:0.998387, test_auc:0.927468, test_auc_max:0.940122\n",
            "epoch: 121, train_auc:0.998917, test_auc:0.933215, test_auc_max:0.940122\n",
            "epoch: 122, train_auc:0.998729, test_auc:0.933152, test_auc_max:0.940122\n",
            "epoch: 123, train_auc:0.998940, test_auc:0.930784, test_auc_max:0.940122\n",
            "epoch: 124, train_auc:0.998847, test_auc:0.932647, test_auc_max:0.940122\n",
            "epoch: 125, train_auc:0.998852, test_auc:0.932615, test_auc_max:0.940122\n",
            "epoch: 126, train_auc:0.998357, test_auc:0.932834, test_auc_max:0.940122\n",
            "epoch: 127, train_auc:0.999074, test_auc:0.931572, test_auc_max:0.940122\n",
            "epoch: 128, train_auc:0.998994, test_auc:0.931466, test_auc_max:0.940122\n",
            "epoch: 129, train_auc:0.998907, test_auc:0.935403, test_auc_max:0.940122\n",
            "epoch: 130, train_auc:0.999179, test_auc:0.933693, test_auc_max:0.940122\n",
            "epoch: 131, train_auc:0.999100, test_auc:0.930049, test_auc_max:0.940122\n",
            "epoch: 132, train_auc:0.999169, test_auc:0.932880, test_auc_max:0.940122\n",
            "epoch: 133, train_auc:0.999225, test_auc:0.931803, test_auc_max:0.940122\n",
            "epoch: 134, train_auc:0.999344, test_auc:0.929539, test_auc_max:0.940122\n",
            "epoch: 135, train_auc:0.999399, test_auc:0.927087, test_auc_max:0.940122\n",
            "epoch: 136, train_auc:0.999156, test_auc:0.929486, test_auc_max:0.940122\n",
            "epoch: 137, train_auc:0.999149, test_auc:0.930402, test_auc_max:0.940122\n",
            "epoch: 138, train_auc:0.999433, test_auc:0.927227, test_auc_max:0.940122\n",
            "epoch: 139, train_auc:0.999583, test_auc:0.933672, test_auc_max:0.940122\n",
            "epoch: 140, train_auc:0.999505, test_auc:0.930346, test_auc_max:0.940122\n",
            "epoch: 141, train_auc:0.999688, test_auc:0.928210, test_auc_max:0.940122\n",
            "epoch: 142, train_auc:0.999666, test_auc:0.927782, test_auc_max:0.940122\n",
            "epoch: 143, train_auc:0.999534, test_auc:0.931753, test_auc_max:0.940122\n",
            "epoch: 144, train_auc:0.999738, test_auc:0.928335, test_auc_max:0.940122\n",
            "epoch: 145, train_auc:0.999555, test_auc:0.926787, test_auc_max:0.940122\n",
            "epoch: 146, train_auc:0.999587, test_auc:0.930342, test_auc_max:0.940122\n",
            "epoch: 147, train_auc:0.999762, test_auc:0.928849, test_auc_max:0.940122\n",
            "epoch: 148, train_auc:0.999720, test_auc:0.927417, test_auc_max:0.940122\n",
            "epoch: 149, train_auc:0.999773, test_auc:0.928858, test_auc_max:0.940122\n",
            "Reducing learning rate to 0.00100 (0.00100) @ T=4300!\n",
            "Updating regularizer @ T=4300!\n",
            "epoch: 150, train_auc:0.999797, test_auc:0.927707, test_auc_max:0.940122\n",
            "epoch: 151, train_auc:0.999852, test_auc:0.928565, test_auc_max:0.940122\n",
            "epoch: 152, train_auc:0.999848, test_auc:0.928148, test_auc_max:0.940122\n",
            "epoch: 153, train_auc:0.999801, test_auc:0.928545, test_auc_max:0.940122\n",
            "epoch: 154, train_auc:0.999757, test_auc:0.929591, test_auc_max:0.940122\n",
            "epoch: 155, train_auc:0.999882, test_auc:0.928305, test_auc_max:0.940122\n",
            "epoch: 156, train_auc:0.999824, test_auc:0.928907, test_auc_max:0.940122\n",
            "epoch: 157, train_auc:0.999813, test_auc:0.928016, test_auc_max:0.940122\n",
            "epoch: 158, train_auc:0.999890, test_auc:0.928964, test_auc_max:0.940122\n",
            "epoch: 159, train_auc:0.999880, test_auc:0.929521, test_auc_max:0.940122\n",
            "epoch: 160, train_auc:0.999945, test_auc:0.928555, test_auc_max:0.940122\n",
            "epoch: 161, train_auc:0.999854, test_auc:0.929472, test_auc_max:0.940122\n",
            "epoch: 162, train_auc:0.999854, test_auc:0.929362, test_auc_max:0.940122\n",
            "epoch: 163, train_auc:0.999786, test_auc:0.928904, test_auc_max:0.940122\n",
            "epoch: 164, train_auc:0.999900, test_auc:0.928410, test_auc_max:0.940122\n",
            "epoch: 165, train_auc:0.999835, test_auc:0.928756, test_auc_max:0.940122\n",
            "epoch: 166, train_auc:0.999859, test_auc:0.929126, test_auc_max:0.940122\n",
            "epoch: 167, train_auc:0.999891, test_auc:0.928517, test_auc_max:0.940122\n",
            "epoch: 168, train_auc:0.999928, test_auc:0.928033, test_auc_max:0.940122\n",
            "epoch: 169, train_auc:0.999860, test_auc:0.927838, test_auc_max:0.940122\n",
            "epoch: 170, train_auc:0.999880, test_auc:0.928455, test_auc_max:0.940122\n",
            "epoch: 171, train_auc:0.999912, test_auc:0.929068, test_auc_max:0.940122\n",
            "epoch: 172, train_auc:0.999866, test_auc:0.929045, test_auc_max:0.940122\n",
            "epoch: 173, train_auc:0.999933, test_auc:0.928420, test_auc_max:0.940122\n",
            "epoch: 174, train_auc:0.999900, test_auc:0.929378, test_auc_max:0.940122\n",
            "epoch: 175, train_auc:0.999897, test_auc:0.930053, test_auc_max:0.940122\n",
            "epoch: 176, train_auc:0.999889, test_auc:0.928431, test_auc_max:0.940122\n",
            "epoch: 177, train_auc:0.999916, test_auc:0.929192, test_auc_max:0.940122\n",
            "epoch: 178, train_auc:0.999916, test_auc:0.928675, test_auc_max:0.940122\n",
            "epoch: 179, train_auc:0.999877, test_auc:0.928343, test_auc_max:0.940122\n",
            "epoch: 180, train_auc:0.999935, test_auc:0.927644, test_auc_max:0.940122\n",
            "epoch: 181, train_auc:0.999961, test_auc:0.928844, test_auc_max:0.940122\n",
            "epoch: 182, train_auc:0.999895, test_auc:0.928445, test_auc_max:0.940122\n",
            "epoch: 183, train_auc:0.999968, test_auc:0.929588, test_auc_max:0.940122\n",
            "epoch: 184, train_auc:0.999951, test_auc:0.929404, test_auc_max:0.940122\n",
            "epoch: 185, train_auc:0.999944, test_auc:0.929707, test_auc_max:0.940122\n",
            "epoch: 186, train_auc:0.999878, test_auc:0.928900, test_auc_max:0.940122\n",
            "epoch: 187, train_auc:0.999880, test_auc:0.928074, test_auc_max:0.940122\n",
            "epoch: 188, train_auc:0.999905, test_auc:0.928266, test_auc_max:0.940122\n",
            "epoch: 189, train_auc:0.999919, test_auc:0.928656, test_auc_max:0.940122\n",
            "epoch: 190, train_auc:0.999909, test_auc:0.927884, test_auc_max:0.940122\n",
            "epoch: 191, train_auc:0.999927, test_auc:0.928053, test_auc_max:0.940122\n",
            "epoch: 192, train_auc:0.999873, test_auc:0.927826, test_auc_max:0.940122\n",
            "epoch: 193, train_auc:0.999899, test_auc:0.928341, test_auc_max:0.940122\n",
            "epoch: 194, train_auc:0.999857, test_auc:0.927969, test_auc_max:0.940122\n",
            "epoch: 195, train_auc:0.999970, test_auc:0.928714, test_auc_max:0.940122\n",
            "epoch: 196, train_auc:0.999926, test_auc:0.928282, test_auc_max:0.940122\n",
            "epoch: 197, train_auc:0.999955, test_auc:0.927949, test_auc_max:0.940122\n",
            "epoch: 198, train_auc:0.999936, test_auc:0.927861, test_auc_max:0.940122\n",
            "epoch: 199, train_auc:0.999893, test_auc:0.927270, test_auc_max:0.940122\n"
          ]
        }
      ]
    }
  ]
}